{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #for array manipulation\n",
    "import pytesseract  #for OCR(Optical Character Recognition)\n",
    "import cv2          #for Image Processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize the captured image for better vision\n",
    "image = cv2.imread('E:\\\\B.Tech SEM-5\\\\TCS\\\\car.jpeg')\n",
    "cv2.resize(image,(int(image.shape[0]),int(500)))\n",
    "cv2.imshow('Original Image',image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert RGB image to Gray-Scale image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#reduce unwanted noise and keeping edges fairly sharp of input image\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "#edge detection of input image \n",
    "edged = cv2.Canny(gray, 170, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join same intensity pixels in edge detected area of the image which is reduce by above used filter\n",
    "cnts = sorted(cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0], key = cv2.contourArea, reverse = True)[:30] \n",
    "\n",
    "NumberPlateCnt = None \n",
    "count = 0\n",
    "\n",
    "#shape analysis of image \n",
    "for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:  \n",
    "            NumberPlateCnt = approx \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking the part other than the number plate\n",
    "mask = np.zeros(gray.shape,np.uint8)     \n",
    "new_image = cv2.drawContours(mask,[NumberPlateCnt],0,255,-1)  #draw the shape which is analysied above\n",
    "new_image = cv2.bitwise_and(image,image,mask=mask)            #extract target part of the image with the use of mask\n",
    "cv2.imshow(\"Final Image\",new_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration for pytesseract\n",
    "config = ('-l eng --oem 1 --psm 3')\n",
    "\n",
    "#run pytesseract OCR on image\n",
    "text = pytesseract.image_to_string(new_image, config=config)\n",
    "\n",
    "#print recognized text\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
